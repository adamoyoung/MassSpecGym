{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helper functions\n",
    "\n",
    "def parse_ce_str(ce_str):\n",
    "\n",
    "    ce_str = str(ce_str)\n",
    "    normal_regex = re.compile(r'\\d+(\\.\\d+)?')\n",
    "    # ramped_regex = re.compile(r'\\d+(\\.\\d+)?-\\d+(\\.\\d+)?')\n",
    "    ramped_regex = re.compile(r'\\d+(\\.\\d+)?(V)?(-|->)\\d+(\\.\\d+)?(V)?')\n",
    "    ce_str = ce_str.split(\";\")[-1]\n",
    "    try:\n",
    "        if \"%\" in ce_str:\n",
    "            normalized = True\n",
    "        else:\n",
    "            normalized = False\n",
    "        if \"-\" in ce_str or \"Ramp\" in ce_str or \"RAMP\" in ce_str or \"->\" in ce_str:\n",
    "            ramped = True\n",
    "            ramped_ce = ramped_regex.search(ce_str).group(0)\n",
    "            if \"->\" in ramped_ce:\n",
    "                min_ce, max_ce = ramped_ce.split(\"->\")\n",
    "            else:\n",
    "                min_ce, max_ce = ramped_ce.split(\"-\")\n",
    "            ce = 0.5*float(min_ce.strip(\"V\")) + 0.5*float(max_ce.strip(\"V\"))\n",
    "        else:\n",
    "            ramped = False\n",
    "            ce = normal_regex.search(ce_str).group(0)\n",
    "            ce = float(ce)\n",
    "    except:\n",
    "        ce = np.nan\n",
    "        normalized = False\n",
    "        ramped = False\n",
    "    return ce, normalized, ramped\n",
    "\n",
    "def convert_nce(row):\n",
    "    # assumes charge factor of 1\n",
    "    if row[\"normalized\"]:\n",
    "        nce = row[\"ce\"]\n",
    "        ace = (nce * row[\"precursor_mz\"] * 1.) / 500.\n",
    "    else:\n",
    "        ace = row[\"ce\"]\n",
    "    return ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fp = \"/scratch/hdd001/home/adamo/neurips_msms_library/neurips_library_positive_df_2.csv\"\n",
    "df_fp = \"/scratch/hdd001/home/adamo/neurips_msms_library/MassSpecGym_labeled_data_df.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44471/274244750.py:1: DtypeWarning: Columns (0,2,3,5,6,7,8,10,11,12,13,16,17,18,20,22,23,24,25,26,27,29,30,31,33,34,35,36,38,39,40,41,42,43,44,49,50,52,53,55,56,57,58,59,61,63,64,65,66,67,68,69,70,72,73,74,75,78,81,83,86,87,88,89,90,91,92,94,95,96,97,98,99,100,102,103,104,105,106,107,108,109,110,111,112,113,114,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,138,139,140,141,142,143,144,147,149,150,151,152,153,154,155,156,157,158,159,160,161,162,164,165,167,168,169,170,172,174,175,176,177,179,180,181,183,184,185,188,189,190,191,193,194,200,201,202,203,206,207,208,209,210,212,213,214) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(df_fp)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(df_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448979, 215)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_per_mol_analysis(df):\n",
    "    # get distribution of number of spectra per molecule\n",
    "    assert not df[\"inchikey\"].isna().any()\n",
    "    spec_per_mol = df[[\"inchikey\"]].groupby(\"inchikey\").size().reset_index(name='counts')\n",
    "    print(spec_per_mol[\"counts\"].describe())\n",
    "    counts, bins = np.histogram(spec_per_mol[\"counts\"].to_numpy(), bins=np.arange(0, 25, 3))\n",
    "    last_counts = (spec_per_mol[\"counts\"].to_numpy() > bins[-1]).sum()\n",
    "    total_counts = np.sum(counts) + last_counts\n",
    "    assert total_counts == df[\"inchikey\"].nunique()\n",
    "    percents = 100 * counts / total_counts\n",
    "    count_counts, _ = np.histogram(spec_per_mol[\"counts\"].to_numpy(), bins=bins, weights=spec_per_mol[\"counts\"].to_numpy())\n",
    "    last_count_counts = ((spec_per_mol[\"counts\"].to_numpy() > bins[-1]) * spec_per_mol[\"counts\"].to_numpy()).sum()\n",
    "    total_count_counts = np.sum(count_counts) + last_count_counts\n",
    "    assert total_count_counts == df.shape[0]\n",
    "    count_percents = 100 * count_counts / total_count_counts\n",
    "    for i in range(len(percents)):\n",
    "        print(f\"| ({bins[i]},{bins[i+1]}] | {percents[i]:.1f} % | {count_percents[i]:.1f} % |\")\n",
    "    print(f\"| ({bins[-1]},inf) | {100 * last_counts / total_counts:.1f} % | {100 * last_count_counts / total_count_counts:.1f} % |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    36752.000000\n",
      "mean        12.216451\n",
      "std         31.976222\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          3.000000\n",
      "75%          8.000000\n",
      "max        998.000000\n",
      "Name: counts, dtype: float64\n",
      "| (0,3] | 29.4 % | 3.5 % |\n",
      "| (3,6] | 40.2 % | 11.3 % |\n",
      "| (6,9] | 6.9 % | 3.8 % |\n",
      "| (9,12] | 4.1 % | 3.3 % |\n",
      "| (12,15] | 2.9 % | 3.1 % |\n",
      "| (15,18] | 2.5 % | 3.3 % |\n",
      "| (18,21] | 1.5 % | 2.3 % |\n",
      "| (21,24] | 1.4 % | 2.5 % |\n",
      "| (24,inf) | 11.2 % | 67.1 % |\n"
     ]
    }
   ],
   "source": [
    "spec_per_mol_analysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charge                         0\n",
      "precursor_mz                   0\n",
      "smiles                         0\n",
      "inchikey                       0\n",
      "adduct                         0\n",
      "peaks_json                     0\n",
      "id                             0\n",
      "parent_mass                    0\n",
      "inchi                          0\n",
      "ionmode                        0\n",
      "compound_name               1771\n",
      "ms_level                    3245\n",
      "instrument_type            10564\n",
      "spectrum_id                47692\n",
      "scans                     120601\n",
      "database_origin           120601\n",
      "principal_investigator    120631\n",
      "data_collector            121254\n",
      "file_name                 168293\n",
      "peptide_sequence          168293\n",
      "confidence                168293\n",
      "submit_user               168293\n",
      "organism_name             168293\n",
      "formula                   260695\n",
      "num_peaks                 280686\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "columns = sorted(df.columns)\n",
    "columns_by_nans = df.isna().sum().sort_values(ascending=True)\n",
    "print(columns_by_nans[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291230\n",
      "collision_energy\n",
      "60.0     14636\n",
      "20.0     14464\n",
      "30.0      6200\n",
      "6V        5930\n",
      "10 eV     5449\n",
      "15.0      4741\n",
      "40        3501\n",
      "45.0      3446\n",
      "30        3345\n",
      "20 eV     3225\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ce_col = \"collision_energy\"\n",
    "print(df[ce_col].isna().sum())\n",
    "print(df[ce_col].value_counts()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "adduct\n",
      "[M+H]+         302835\n",
      "[M+Na]+        118040\n",
      "[M+NH4]+        12830\n",
      "[M-H2O+H]+       6671\n",
      "[2M+H]+          1792\n",
      "[2M+Na]+         1657\n",
      "[M-2H2O+H]+      1312\n",
      "[M+K]+           1188\n",
      "[M]+              945\n",
      "[M+2H]2+          657\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "adduct_col = \"adduct\"\n",
    "print(df[adduct_col].isna().sum())\n",
    "print(df[adduct_col].value_counts()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10564\n",
      "instrument_type\n",
      "ESI-ITFT             222251\n",
      "LC-ESI-QTOF           69842\n",
      "LC-ESI-ITFT           61678\n",
      "Orbitrap              47693\n",
      "LC-ESI-QFT            21954\n",
      "ESI-QTOF               9562\n",
      "ESI-QFT                4759\n",
      "LC-Q-TOF/MS             172\n",
      "LC-ESI-QEHF             144\n",
      "LC-ESI-Q-Orbitrap       108\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "inst_col = \"instrument_type\"\n",
    "print(df[inst_col].isna().sum())\n",
    "print(df[inst_col].value_counts()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3245\n",
      "ms_level\n",
      "2      303802\n",
      "MS2    116961\n",
      "2       24576\n",
      "MS1       334\n",
      "MS         61\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "level_col = \"ms_level\"\n",
    "print(df[level_col].isna().sum())\n",
    "print(df[level_col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collision energy filter: 0.35135050859839767\n",
      "adduct filter: 0.9374046447606681\n",
      "instrument filter: 0.3425772697609465\n",
      "prec_mz_filter: 1.0\n",
      "level filter: 0.9918927165858537\n",
      "intersection filter: 0.26731762510050583\n"
     ]
    }
   ],
   "source": [
    "adducts = [\n",
    "    \"[M+H]+\",\n",
    "    \"[M+Na]+\"\n",
    "]\n",
    "\n",
    "inst_types_map = {\n",
    "    # \"ESI-ITFT\": \"ITFT\",\n",
    "    \"LC-ESI-QTOF\": \"QTOF\",\n",
    "    # \"LC-ESI_ITFT\": \"ITFT\",\n",
    "    \"Orbitrap\": \"Orbitrap\",\n",
    "    \"LC-ESI-QFT\": \"QFT\",\n",
    "    \"ESI-QTOF\": \"QTOF\",\n",
    "    \"ESI-QFT\": \"QFT\"\n",
    "}\n",
    "\n",
    "def get_filter(df):\n",
    "\n",
    "    ce_filter = ~(df[\"collision_energy\"].isna())\n",
    "    adduct_filter = df[\"adduct\"].isin(adducts)\n",
    "    inst_filter = ~(df[\"instrument_type\"].map(inst_types_map).isna())\n",
    "    prec_mz_filter = ~(df[\"precursor_mz\"].isna())\n",
    "    level_filter = df[\"ms_level\"].isin([2,\"2\",\"MS2\"])\n",
    "    all_filter = ce_filter & adduct_filter & inst_filter & prec_mz_filter & level_filter\n",
    "    print(\"collision energy filter:\",ce_filter.mean())\n",
    "    print(\"adduct filter:\",adduct_filter.mean())\n",
    "    print(\"instrument filter:\",inst_filter.mean())\n",
    "    print(\"prec_mz_filter:\",prec_mz_filter.mean())\n",
    "    print(\"level filter:\",level_filter.mean())\n",
    "    print(\"intersection filter:\",all_filter.mean())\n",
    "    return all_filter\n",
    "\n",
    "all_filter = get_filter(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num spectra: 120020\n",
      "num compounds: 19265\n",
      "adduct\n",
      "[M+H]+     115023\n",
      "[M+Na]+      4997\n",
      "Name: count, dtype: int64\n",
      "instrument_type\n",
      "LC-ESI-QTOF    52284\n",
      "Orbitrap       41356\n",
      "LC-ESI-QFT     21432\n",
      "ESI-QFT         3089\n",
      "ESI-QTOF        1859\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "filter_df = df[all_filter].copy(deep=True)\n",
    "print(\"num spectra:\", filter_df.shape[0])\n",
    "print(\"num compounds:\", filter_df[\"inchikey\"].nunique())\n",
    "print(filter_df[\"adduct\"].value_counts())\n",
    "print(filter_df[\"instrument_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['65HCD' '45HCD' '35HCD' '60.0' '20.0' '15.0' '20 V' '10 V' '40 V' '30.0']\n"
     ]
    }
   ],
   "source": [
    "ces = filter_df[\"collision_energy\"].unique()\n",
    "print(ces[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce              2\n",
      "normalized      0\n",
      "ramped          0\n",
      "precursor_mz    0\n",
      "dtype: int64\n",
      "normalized\n",
      "False    114770\n",
      "True       5250\n",
      "Name: count, dtype: int64\n",
      "ramped\n",
      "False    115566\n",
      "True       4454\n",
      "Name: count, dtype: int64\n",
      "2\n",
      "2\n",
      "0.9999833361106483\n"
     ]
    }
   ],
   "source": [
    "# standardize CEs\n",
    "# try to parse them\n",
    "ce_vals = filter_df[\"collision_energy\"].apply(parse_ce_str)\n",
    "ce_df = pd.DataFrame(ce_vals.tolist(), columns=[\"ce\",\"normalized\",\"ramped\"])\n",
    "ce_df.index = filter_df.index\n",
    "ce_df = pd.concat([ce_df,filter_df[[\"precursor_mz\"]]],axis=1)\n",
    "print(ce_df.isna().sum())\n",
    "print(ce_df[\"normalized\"].value_counts())\n",
    "print(ce_df[\"ramped\"].value_counts())\n",
    "# convert normalized to absolute\n",
    "ce = ce_df.apply(convert_nce,axis=1)\n",
    "print(ce.isna().sum())\n",
    "ce_df.loc[:,\"ce\"] = ce\n",
    "print(ce_df[\"ce\"].isna().sum())\n",
    "ce_filter_2 = ~(ce_df[\"ce\"].isna())\n",
    "print(ce_filter_2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num spectra: 120018\n",
      "num compounds: 19265\n",
      "adduct\n",
      "[M+H]+     115021\n",
      "[M+Na]+      4997\n",
      "Name: count, dtype: int64\n",
      "instrument_type\n",
      "LC-ESI-QTOF    52282\n",
      "Orbitrap       41356\n",
      "LC-ESI-QFT     21432\n",
      "ESI-QFT         3089\n",
      "ESI-QTOF        1859\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get subset that can handle ces and pass previous filters\n",
    "all_filter_2 = all_filter & ce_filter_2\n",
    "filter_df_2 = df[all_filter_2].copy(deep=True)\n",
    "print(\"num spectra:\", filter_df_2.shape[0])\n",
    "print(\"num compounds:\", filter_df_2[\"inchikey\"].nunique())\n",
    "print(filter_df_2[\"adduct\"].value_counts())\n",
    "print(filter_df_2[\"instrument_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize ces (rename to ce, to avoid overwriting collision_energy)\n",
    "ce_vals = filter_df_2[\"collision_energy\"].apply(parse_ce_str)\n",
    "ce_df = pd.DataFrame(ce_vals.tolist(), columns=[\"ce\",\"normalized\",\"ramped\"])\n",
    "ce_df.index = filter_df_2.index\n",
    "ce_df = pd.concat([ce_df,filter_df_2[[\"precursor_mz\"]]],axis=1)\n",
    "ce = ce_df.apply(convert_nce,axis=1)\n",
    "ce_df.loc[:,\"ce\"] = ce\n",
    "assert not ce_df[\"ce\"].isna().any()\n",
    "filter_df_2.loc[:,\"ce\"] = ce_df[\"ce\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize instrument types (rename to inst_type, to avoid overwriting instrument_type)\n",
    "filter_df_2.loc[:,\"inst_type\"] = filter_df_2[\"instrument_type\"].map(inst_types_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ce           0\n",
      "adduct       0\n",
      "inst_type    0\n",
      "dtype: int64\n",
      "count    120018.000000\n",
      "mean         39.696305\n",
      "std          30.907380\n",
      "min           0.000000\n",
      "25%          20.000000\n",
      "50%          30.000000\n",
      "75%          60.000000\n",
      "max         376.392708\n",
      "Name: ce, dtype: float64\n",
      "adduct\n",
      "[M+H]+     115021\n",
      "[M+Na]+      4997\n",
      "Name: count, dtype: int64\n",
      "inst_type\n",
      "QTOF        54141\n",
      "Orbitrap    41356\n",
      "QFT         24521\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# verify that there are no nans\n",
    "print(filter_df_2[[\"ce\",\"adduct\",\"inst_type\"]].isna().sum())\n",
    "# summarize metadata\n",
    "print(filter_df_2[\"ce\"].describe())\n",
    "print(filter_df_2[\"adduct\"].value_counts())\n",
    "print(filter_df_2[\"inst_type\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    19265.000000\n",
      "mean         6.229847\n",
      "std          8.304412\n",
      "min          1.000000\n",
      "25%          3.000000\n",
      "50%          3.000000\n",
      "75%          6.000000\n",
      "max        144.000000\n",
      "Name: counts, dtype: float64\n",
      "| (0,3] | 15.1 % | 4.1 % |\n",
      "| (3,6] | 58.9 % | 29.9 % |\n",
      "| (6,9] | 7.3 % | 7.7 % |\n",
      "| (9,12] | 4.5 % | 7.0 % |\n",
      "| (12,15] | 3.9 % | 7.8 % |\n",
      "| (15,18] | 3.0 % | 7.7 % |\n",
      "| (18,21] | 1.5 % | 4.6 % |\n",
      "| (21,24] | 1.5 % | 5.5 % |\n",
      "| (24,inf) | 4.3 % | 25.8 % |\n"
     ]
    }
   ],
   "source": [
    "spec_per_mol_analysis(filter_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec_id             120018\n",
      "mol_id               19265\n",
      "adduct                   2\n",
      "instrument_type          3\n",
      "collision_energy      4056\n",
      "precursor_mz         20456\n",
      "inchikey             19265\n",
      "smiles               19566\n",
      "spectrum            118287\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "proc_df = filter_df_2[[\"ce\",\"adduct\",\"inst_type\",\"inchikey\",\"smiles\",\"peaks_json\",\"precursor_mz\"]].copy(deep=True)\n",
    "proc_df = proc_df.rename(columns={\"ce\":\"collision_energy\",\"inst_type\":\"instrument_type\",\"peaks_json\":\"spectrum\"})\n",
    "proc_df[\"spec_id\"] = np.arange(proc_df.shape[0])\n",
    "inchikey_to_id = {ik:idx for idx, ik in enumerate(sorted(proc_df[\"inchikey\"].unique()))}\n",
    "proc_df[\"mol_id\"] = proc_df[\"inchikey\"].map(inchikey_to_id)\n",
    "proc_df = proc_df[[\"spec_id\",\"mol_id\",\"adduct\",\"instrument_type\",\"collision_energy\",\"precursor_mz\",\"inchikey\",\"smiles\",\"spectrum\"]]\n",
    "assert ~(proc_df.isna().any().any())\n",
    "print(proc_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_df.to_csv(\"../data/debug/simulation_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller version for debugging\n",
    "small_proc_df = proc_df.sample(n=10000, replace=False, random_state=420)\n",
    "small_proc_df.to_csv(\"../data/debug/simulation_small_df.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FRAG-GNN-GPU4-DEBUG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
