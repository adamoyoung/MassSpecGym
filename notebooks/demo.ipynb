{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "import massspecgym.utils as utils\n",
    "from massspecgym.data import MassSpecDataset, RetrievalDataset, MassSpecDataModule\n",
    "from massspecgym.data.transforms import SpecTokenizer, MolFingerprinter, SpecBinner\n",
    "from massspecgym.models.retrieval import DeepSetsRetrieval, RandomRetrieval, FingerprintFFNRetrieval, FromDictRetrieval\n",
    "from massspecgym.models.de_novo import DummyDeNovo, RandomDeNovo, SmilesTransformer\n",
    "from massspecgym.models.tokenizers import SmilesBPETokenizer, SelfiesTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 0\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(0)\n",
    "\n",
    "DEBUG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    mgf_pth = Path(\"../data/debug/example_5_spectra.mgf\")\n",
    "    candidates_pth = Path(\"../data/debug/example_5_spectra_candidates.json\")\n",
    "    split_pth=Path(\"../data/debug/example_5_spectra_split.tsv\")\n",
    "else:\n",
    "    # Use default benchmark paths\n",
    "    # mgf_pth = None\n",
    "    # candidates_pth = None\n",
    "    # split_pth = None\n",
    "    mgf_pth = Path(\"../data/MassSpecGym_with_test/MassSpecGym_with_test.tsv\")\n",
    "    candidates_pth = Path(\"../data/MassSpecGym_with_test/MassSpecGym_retrieval_candidates_formula_with_test.json\")\n",
    "    split_pth = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Sets model on the fingerprint retrieval task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RetrievalDataset(\n",
    "    pth=mgf_pth,\n",
    "    spec_transform=SpecTokenizer(n_peaks=60),\n",
    "    mol_transform=MolFingerprinter(),\n",
    "    candidates_pth=candidates_pth,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "# Uncomment the paths to use debugging data containing only 5 spectra\n",
    "dataset = RetrievalDataset(\n",
    "    pth=mgf_pth,\n",
    "    spec_transform=SpecTokenizer(n_peaks=60),\n",
    "    mol_transform=MolFingerprinter(),\n",
    "    candidates_pth=candidates_pth,\n",
    ")\n",
    "\n",
    "# Init data module\n",
    "data_module = MassSpecDataModule(\n",
    "    dataset=dataset,\n",
    "    split_pth=split_pth,\n",
    "    batch_size=3\n",
    ")\n",
    "\n",
    "# Init model\n",
    "model = DeepSetsRetrieval(\n",
    "    bootstrap_metrics=True,\n",
    "    df_test_path='./df_test.pkl',\n",
    "    out_channels=2048,\n",
    "    fourier_features=True\n",
    ")\n",
    "# model = RandomRetrieval()\n",
    "\n",
    "# Init logger\n",
    "# You may need to run wandb init first to use the wandb logger\n",
    "# Alternatively set logger = None in Trainer below not to use wandb\n",
    "project = \"MassSpecGymRetrieval\"\n",
    "name = \"DeepSets\"\n",
    "logger = pl.loggers.WandbLogger(\n",
    "    project=project,\n",
    "    name=name,\n",
    "    tags=[],\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "# Init trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\", max_epochs=50, logger=logger, log_every_n_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: adamo-young. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250116_233905-h9oymy96</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamo-young/MassSpecGymRetrieval/runs/h9oymy96' target=\"_blank\">DeepSets</a></strong> to <a href='https://wandb.ai/adamo-young/MassSpecGymRetrieval' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamo-young/MassSpecGymRetrieval' target=\"_blank\">https://wandb.ai/adamo-young/MassSpecGymRetrieval</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamo-young/MassSpecGymRetrieval/runs/h9oymy96' target=\"_blank\">https://wandb.ai/adamo-young/MassSpecGymRetrieval/runs/h9oymy96</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6ad6d10ae3423cb48fa54b460e4dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      " val_fingerprint_cos_sim    0.1643836945295334\n",
      "     val_hit_rate@1                 0.0\n",
      "     val_hit_rate@20                1.0\n",
      "     val_hit_rate@5                 1.0\n",
      "        val_loss            0.8356163501739502\n",
      "       val_mces@1                  19.5\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n",
      "\n",
      "   | Name                    | Type             | Params\n",
      "--------------------------------------------------------------\n",
      "0  | ff                      | FourierFeatures  | 6.0 K \n",
      "1  | ff_proj_mz              | Linear           | 4.9 M \n",
      "2  | ff_proj_i               | Linear           | 206   \n",
      "3  | phi                     | MLP              | 525 K \n",
      "4  | rho                     | MLP              | 1.3 M \n",
      "5  | loss_fn                 | CosSimLoss       | 0     \n",
      "6  | val_fingerprint_cos_sim | CosineSimilarity | 0     \n",
      "7  | val_hit_rate@1          | MeanMetric       | 0     \n",
      "8  | val_hit_rate@5          | MeanMetric       | 0     \n",
      "9  | val_hit_rate@20         | MeanMetric       | 0     \n",
      "10 | val_mces@1              | MeanMetric       | 0     \n",
      "--------------------------------------------------------------\n",
      "6.7 M     Trainable params\n",
      "6.0 K     Non-trainable params\n",
      "6.8 M     Total params\n",
      "27.003    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7fe2facafe4cdd83532b410a5ca944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5fb1ac57764737bd2dbdcb724337a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23743736ce8429486f0de3ad6cc7187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7ddfd2b9864a9fa592bace01ecf1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b96dfe850654e1ea716b85c768e83d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f74e517233647719ee74b7066194d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614ce959831a4884b4b458e48e579cf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fbc616a4124b828e9fcc4cc412f2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc24c6c986642d7a6fd0c0d82c42547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01480b3e1f474168bed4e02dc824dd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253bbb77c48a4119a9c17876f09141f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fd19edc73d4a82aac3a6cb08be0e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b90ee4f0294fd1931f374ae43e0e9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482e0ef80fc4412da0b9e15b1a350531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2f9369089a431995f80d23a64d76f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8915aebfce29496aa6d94e9d1c09fd64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3885390f096a4ef0bc7d71b756203567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce12b9887355440eb3c99c3f1807655d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac06343be284f83a91ea3601eb035bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f3ff00bd7044b39b567bc5b5f43558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "965223716d674113a7581b0a1274a27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8263cac83d46435699bb4e393320cf3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8f9a8e0e8a4280832cf19a3abd1a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a48cc4aa46a04f09bd8cef9bcc758576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a463279978d241e1863d6ec3f191ce67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae39505264b40ba96b5d69eefe95a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce27a444b1ea49818858257009d73efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802d85fd394c41cea5c9b036f6e78562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c168290f2b54ed39548c3be3d8bd31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7305e95ebfe34785b54c6bd425a5ac07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2697479ba14e869319558345eeb5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff59f887cc14ba29a954a35e813d881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b57429304d4fd597f01e089483e064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a114e2d041481b91a5f14c6a292e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c0506b87eb4efcb72aeef396122218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9cd50b69bc74567949cd4e4aefa4511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af507ec722e44062b01e78b042bbdc5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcdc901cb55497c9a2d3d2afc0248b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f51060575248ae858accb0e3383f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67696fb9b3242c3b286b253839b8587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c40122cd87417da676e956a0ef4d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0b585a646c44ab8dabc6943db0250a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972185728e234ce2869e5c94a395290d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de8458437f34fbda70cc0ad9fa6965c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d67a7e1cb3844e9a34495dfdb11378e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f3897623d149d38c59fa47f9d88d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04ed659e14744e5fae29ed9c175b9d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf14a601c804221a94d5357bc829dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d948d856d2ad4c24a347b51150b68463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb8ee3208e24a439e375b575ea52a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fceaa29cfe05435d9c25e182bcc90fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f577cd6e3a84b6fa0496a0816619d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63358b8f1d904998bf0d3beb36042b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: The ``compute`` method of metric MeanMetric was called before the ``update`` method which may lead to errors, as metric states have not yet been updated.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "test_fingerprint_cos_sim    0.22373272478580475\n",
      "     test_hit_rate@1                0.0\n",
      "   test_hit_rate@1_std              nan\n",
      "    test_hit_rate@20                0.0\n",
      "  test_hit_rate@20_std              nan\n",
      "     test_hit_rate@5                0.0\n",
      "   test_hit_rate@5_std              nan\n",
      "        test_loss           0.7762672901153564\n",
      "       test_mces@1                 28.0\n",
      "     test_mces@1_std                nan\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_fingerprint_cos_sim': 0.22373272478580475,\n",
       "  'test_loss': 0.7762672901153564,\n",
       "  'test_hit_rate@1': 0.0,\n",
       "  'test_hit_rate@1_std': nan,\n",
       "  'test_hit_rate@5': 0.0,\n",
       "  'test_hit_rate@5_std': nan,\n",
       "  'test_hit_rate@20': 0.0,\n",
       "  'test_hit_rate@20_std': nan,\n",
       "  'test_mces@1': 28.0,\n",
       "  'test_mces@1_std': nan}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate before training\n",
    "data_module.prepare_data()  # Explicit call needed for validate before fit\n",
    "data_module.setup()  # Explicit call needed for validate before fit\n",
    "trainer.validate(model, datamodule=data_module)\n",
    "\n",
    "# Train\n",
    "trainer.fit(model, datamodule=data_module)\n",
    "\n",
    "# Train\n",
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random baseline on the fingerprint retrieval task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "fp_size = 4096\n",
    "\n",
    "# Load dataset\n",
    "dataset = RetrievalDataset(\n",
    "    pth=mgf_pth,\n",
    "    spec_transform=SpecBinner(),\n",
    "    mol_transform=MolFingerprinter(fp_size=fp_size),\n",
    "    candidates_pth=candidates_pth,\n",
    ")\n",
    "\n",
    "# Init data module\n",
    "data_module = MassSpecDataModule(\n",
    "    dataset=dataset,\n",
    "    split_pth=split_pth,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# Init model\n",
    "model = RandomRetrieval()\n",
    "\n",
    "# Init logger\n",
    "# You may need to run wandb init first to use the wandb logger\n",
    "# Alternatively set logger = None in Trainer below not to use wandb\n",
    "project = \"MassSpecGymRetrieval\"\n",
    "name = \"RandomFFN\"\n",
    "logger = pl.loggers.WandbLogger(\n",
    "    project=project,\n",
    "    name=name,\n",
    "    tags=[],\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "# Init trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\", max_epochs=50, logger=logger, log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fingerpint FFN model on the fingerprint retrieval task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "fp_size = 4096\n",
    "\n",
    "# Load dataset\n",
    "dataset = RetrievalDataset(\n",
    "    pth=mgf_pth,\n",
    "    spec_transform=SpecBinner(),\n",
    "    mol_transform=MolFingerprinter(fp_size=fp_size),\n",
    "    candidates_pth=candidates_pth,\n",
    ")\n",
    "\n",
    "# Init data module\n",
    "data_module = MassSpecDataModule(\n",
    "    dataset=dataset,\n",
    "    split_pth=split_pth,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# Init model\n",
    "model = FingerprintFFNRetrieval(\n",
    "    in_channels=1005,\n",
    "    out_channels=fp_size,\n",
    ")\n",
    "\n",
    "# Init logger\n",
    "# You may need to run wandb init first to use the wandb logger\n",
    "# Alternatively set logger = None in Trainer below not to use wandb\n",
    "project = \"MassSpecGymRetrieval\"\n",
    "name = \"FingerprintFFN_debug\"\n",
    "logger = pl.loggers.WandbLogger(\n",
    "    project=project,\n",
    "    name=name,\n",
    "    tags=[],\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "# Init trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\", max_epochs=50, logger=logger, log_every_n_steps=50\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIST on the fingerprint retrieval task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fp_size = 4096\n",
    "\n",
    "# # Load dataset\n",
    "# dataset = RetrievalDataset(\n",
    "#     pth=mgf_pth,\n",
    "#     spec_transform=SpecBinner(),\n",
    "#     mol_transform=MolFingerprinter(fp_size=fp_size),\n",
    "#     candidates_pth=candidates_pth,\n",
    "# )\n",
    "\n",
    "# # Init data module\n",
    "# data_module = MassSpecDataModule(\n",
    "#     dataset=dataset,\n",
    "#     split_pth=split_pth,\n",
    "#     batch_size=64\n",
    "# )\n",
    "\n",
    "# # Init model\n",
    "# df = pd.read_pickle('fp_preds_MassSpecGym_df.pkl')\n",
    "# dct = dict(zip(df['name'], df['fp_predict']))\n",
    "# model = FromDictRetrieval(dct=dct)\n",
    "\n",
    "# # Init logger\n",
    "# # You may need to run wandb init first to use the wandb logger\n",
    "# # Alternatively set logger = None in Trainer below not to use wandb\n",
    "# project = \"MassSpecGymRetrieval\"\n",
    "# name = \"MIST\"\n",
    "# logger = pl.loggers.WandbLogger(\n",
    "#     project=project,\n",
    "#     name=name,\n",
    "#     tags=[],\n",
    "#     log_model=False,\n",
    "# )\n",
    "\n",
    "# # Init trainer\n",
    "# trainer = Trainer(\n",
    "#     accelerator=\"cpu\", max_epochs=50, logger=logger, log_every_n_steps=50\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy model on the de novo generation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "# Uncomment the paths to use debugging data containing only 5 spectra\n",
    "dataset = MassSpecDataset(\n",
    "    pth=mgf_pth,\n",
    "    spec_transform=SpecTokenizer(n_peaks=60),\n",
    "    mol_transform=None\n",
    ")\n",
    "\n",
    "# Init data module\n",
    "data_module = MassSpecDataModule(\n",
    "    dataset=dataset,\n",
    "    split_pth=split_pth,\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "# Init model\n",
    "model = DummyDeNovo(\n",
    "    df_test_path='./df_test.pkl'\n",
    ")\n",
    "\n",
    "# Init logger\n",
    "# You may need to run wandb init first to use the wandb logger\n",
    "# Alternatively set logger = None in Trainer below not to use wandb\n",
    "project = \"MassSpecGymDeNovo\"\n",
    "name = \"RandomBasline\"\n",
    "logger = pl.loggers.WandbLogger(\n",
    "    project=project,\n",
    "    name=name,\n",
    "    tags=[],\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "# Init trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\", max_epochs=50, logger=logger, log_every_n_steps=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De novo SMILES transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokenizer on 3947573 SMILES strings.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9959a1bace849c6988bc48c24716df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      Validate metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val_loss               9.059257507324219\n",
      "    val_num_valid_mols                 1.0\n",
      "    val_top_10_accuracy                0.0\n",
      "val_top_10_max_tanimoto_sim   0.036036036908626556\n",
      "   val_top_10_mces_dist               100.0\n",
      "    val_top_1_accuracy                 0.0\n",
      "val_top_1_max_tanimoto_sim    0.036036036908626556\n",
      "    val_top_1_mces_dist               100.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n",
      "\n",
      "   | Name                        | Type             | Params\n",
      "------------------------------------------------------------------\n",
      "0  | src_encoder                 | Linear           | 1.5 K \n",
      "1  | tgt_embedding               | Embedding        | 2.7 M \n",
      "2  | transformer                 | Transformer      | 29.4 M\n",
      "3  | tgt_decoder                 | Linear           | 2.7 M \n",
      "4  | criterion                   | CrossEntropyLoss | 0     \n",
      "5  | val_num_valid_mols          | MeanMetric       | 0     \n",
      "6  | val_top_1_mces_dist         | MeanMetric       | 0     \n",
      "7  | val_top_1_max_tanimoto_sim  | MeanMetric       | 0     \n",
      "8  | val_top_1_accuracy          | MeanMetric       | 0     \n",
      "9  | val_top_10_mces_dist        | MeanMetric       | 0     \n",
      "10 | val_top_10_max_tanimoto_sim | MeanMetric       | 0     \n",
      "11 | val_top_10_accuracy         | MeanMetric       | 0     \n",
      "------------------------------------------------------------------\n",
      "34.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "34.8 M    Total params\n",
      "139.053   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51cf9965269461b88bc02bfa0309be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/torch/nn/functional.py:5193: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dfc77f4e4a947bfaecd164204ad9aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:42:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:34] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:34] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:34] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:34] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:34] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:34] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:48] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:48] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:48] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:48] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:48] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:48] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:54] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:54] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:54] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:54] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:54] Invalid InChI prefix in generating InChI Key\n",
      "[23:42:54] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:06] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:06] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:06] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:06] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:06] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:06] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:11] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:11] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:11] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:11] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:11] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:11] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:24] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:24] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:24] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:24] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:24] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:24] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:29] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:42] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:42] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:42] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:42] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:42] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:42] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:47] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:47] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:47] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:47] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:47] Invalid InChI prefix in generating InChI Key\n",
      "[23:43:47] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:01] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:01] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:01] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:01] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:01] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:01] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:07] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:07] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:07] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:07] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:07] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:07] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:20] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:20] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:20] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:20] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:20] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:20] Invalid InChI prefix in generating InChI Key\n",
      "[23:44:26] non-ring atom 0 marked aromatic\n",
      "[23:44:26] non-ring atom 0 marked aromatic\n",
      "[23:44:26] non-ring atom 0 marked aromatic\n",
      "[23:44:41] non-ring atom 0 marked aromatic\n",
      "[23:44:41] non-ring atom 0 marked aromatic\n",
      "[23:44:41] non-ring atom 0 marked aromatic\n",
      "[23:44:47] non-ring atom 0 marked aromatic\n",
      "[23:44:47] non-ring atom 0 marked aromatic\n",
      "[23:44:47] non-ring atom 0 marked aromatic\n",
      "[23:45:00] non-ring atom 0 marked aromatic\n",
      "[23:45:00] non-ring atom 0 marked aromatic\n",
      "[23:45:00] non-ring atom 0 marked aromatic\n",
      "[23:45:13] non-ring atom 0 marked aromatic\n",
      "[23:45:13] non-ring atom 0 marked aromatic\n",
      "[23:45:13] non-ring atom 0 marked aromatic\n",
      "[23:45:33] non-ring atom 0 marked aromatic\n",
      "[23:45:33] non-ring atom 0 marked aromatic\n",
      "[23:45:33] non-ring atom 0 marked aromatic\n",
      "[23:45:38] non-ring atom 0 marked aromatic\n",
      "[23:45:38] non-ring atom 0 marked aromatic\n",
      "[23:45:38] non-ring atom 0 marked aromatic\n",
      "[23:45:53] non-ring atom 0 marked aromatic\n",
      "[23:45:53] non-ring atom 0 marked aromatic\n",
      "[23:45:53] non-ring atom 0 marked aromatic\n",
      "[23:45:59] non-ring atom 0 marked aromatic\n",
      "[23:45:59] non-ring atom 0 marked aromatic\n",
      "[23:45:59] non-ring atom 0 marked aromatic\n",
      "[23:46:12] non-ring atom 0 marked aromatic\n",
      "[23:46:12] non-ring atom 0 marked aromatic\n",
      "[23:46:12] non-ring atom 0 marked aromatic\n",
      "[23:46:17] non-ring atom 0 marked aromatic\n",
      "[23:46:17] non-ring atom 0 marked aromatic\n",
      "[23:46:17] non-ring atom 0 marked aromatic\n",
      "[23:46:29] non-ring atom 0 marked aromatic\n",
      "[23:46:29] non-ring atom 0 marked aromatic\n",
      "[23:46:29] non-ring atom 0 marked aromatic\n",
      "[23:46:35] non-ring atom 0 marked aromatic\n",
      "[23:46:35] non-ring atom 0 marked aromatic\n",
      "[23:46:35] non-ring atom 0 marked aromatic\n",
      "[23:46:49] non-ring atom 0 marked aromatic\n",
      "[23:48:39] SMILES Parse Error: syntax error while parsing: CC/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c(C@H]2c(C@H]2c2c(C@H]2c(C@H]2c(C@H]2c(C)cccccccccccccccccc\n",
      "[23:48:39] SMILES Parse Error: Failed parsing SMILES 'CC/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c(C@H]2c(C@H]2c2c(C@H]2c(C@H]2c(C@H]2c(C)cccccccccccccccccc' for input: 'CC/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c(C@H]2c(C@H]2c2c(C@H]2c(C@H]2c(C@H]2c(C)cccccccccccccccccc'\n",
      "[23:48:39] SMILES Parse Error: syntax error while parsing: C/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c(C@H]2c(C@H]2c(C)cccccccccccccccccccccccccccccccccccccccccc\n",
      "[23:48:39] SMILES Parse Error: Failed parsing SMILES 'C/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c(C@H]2c(C@H]2c(C)cccccccccccccccccccccccccccccccccccccccccc' for input: 'C/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c(C@H]2c(C@H]2c(C)cccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:48:45] SMILES Parse Error: syntax error while parsing: C/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c(C@H]2c(C@H]2c(C)cccccccccccccccccccccccccccccccccccccccccc\n",
      "[23:48:45] SMILES Parse Error: Failed parsing SMILES 'C/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c(C@H]2c(C@H]2c(C)cccccccccccccccccccccccccccccccccccccccccc' for input: 'C/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c(C@H]2c(C@H]2c(C)cccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:48:45] SMILES Parse Error: syntax error while parsing: C/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c2c(C@H]2c(C@H]2c(C@H]2c(C@H]2c2c(C)cccccccccccccccccccccccc\n",
      "[23:48:45] SMILES Parse Error: Failed parsing SMILES 'C/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c2c(C@H]2c(C@H]2c(C@H]2c(C@H]2c2c(C)cccccccccccccccccccccccc' for input: 'C/C(=O[C@H]2c(C@H]2c(C@H]2c(C@@H]2c(C@H]2c2c(C@H]2c(C@H]2c(C@H]2c(C@H]2c2c(C)cccccccccccccccccccccccc'\n",
      "[23:48:45] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C@H]2(C@@H]2[C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c\n",
      "[23:48:45] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C@H]2(C@@H]2[C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c' for input: 'C/C1=C/CC[C@H]2(C@@H]2[C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c'\n",
      "[23:48:58] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c\n",
      "[23:48:58] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c' for input: 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c'\n",
      "[23:48:58] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c(C)c(C)ccc\n",
      "[23:48:58] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c(C)c(C)ccc' for input: 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c2c(C)c(C)ccc'\n",
      "[23:48:58] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c\n",
      "[23:48:58] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c' for input: 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c'\n",
      "[23:49:04] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@\n",
      "[23:49:04] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@'\n",
      "[23:49:04] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c\n",
      "[23:49:04] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c' for input: 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c'\n",
      "[23:49:04] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(\n",
      "[23:49:04] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(' for input: 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2('\n",
      "[23:49:17] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c\n",
      "[23:49:17] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c' for input: 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c'\n",
      "[23:49:17] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@\n",
      "[23:49:17] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@'\n",
      "[23:49:17] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c\n",
      "[23:49:17] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c' for input: 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2c2c2c2c2c2c2c2c2c2c2c2c2c'\n",
      "[23:49:23] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@\n",
      "[23:49:23] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@'\n",
      "[23:49:23] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@\n",
      "[23:49:23] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@'\n",
      "[23:49:23] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(\n",
      "[23:49:23] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(' for input: 'C/C1=C/CC[C@H]2(C@@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2(C@H]2('\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db4ae6ca8be46f39472f9d7113cd613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:49:29] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@\n",
      "[23:49:29] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@'\n",
      "[23:49:39] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@\n",
      "[23:49:39] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@'\n",
      "[23:49:39] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@\n",
      "[23:49:39] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@'\n",
      "[23:49:39] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@\n",
      "[23:49:39] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@'\n",
      "[23:49:44] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@\n",
      "[23:49:44] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@'\n",
      "[23:49:44] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2\n",
      "[23:49:44] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2'\n",
      "[23:49:44] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2\n",
      "[23:49:44] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2'\n",
      "[23:49:50] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2\n",
      "[23:49:50] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2'\n",
      "[23:49:50] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2\n",
      "[23:49:50] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2'\n",
      "[23:49:50] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2\n",
      "[23:49:50] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2'\n",
      "[23:49:56] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2CC1\n",
      "[23:49:56] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2CC1'\n",
      "[23:49:56] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:49:56] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:49:56] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2CC1\n",
      "[23:49:56] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2CC1'\n",
      "[23:49:58] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2CC1\n",
      "[23:49:58] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@@H]2CC1'\n",
      "[23:49:58] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:49:58] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:49:58] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:49:58] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:01] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:01] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:01] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:01] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:01] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:01] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:06] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:06] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:06] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:06] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:06] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:06] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:08] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:08] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:08] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:08] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:08] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:08] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:14] SMILES Parse Error: unclosed ring for input: 'COc1nccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:50:14] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:14] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:14] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:14] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:19] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:19] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:19] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:19] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:19] SMILES Parse Error: unclosed ring for input: 'COc1nccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:50:25] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:25] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:25] SMILES Parse Error: unclosed ring for input: 'COc1nccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:50:25] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:25] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:31] SMILES Parse Error: unclosed ring for input: 'COc1nccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:50:31] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:31] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:31] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:31] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:36] SMILES Parse Error: unclosed ring for input: 'COc1nccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:50:36] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:36] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:36] SMILES Parse Error: syntax error while parsing: C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1\n",
      "[23:50:36] SMILES Parse Error: Failed parsing SMILES 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1' for input: 'C/C1=C/CC[C)O[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:42] SMILES Parse Error: extra open parentheses for input: 'COc1nccccccccccccccccccccccccccccc(C(=O)ccccccccccccccccccccccccccccccccccccccccccccccccccccccccc(Cl)c'\n",
      "[23:50:42] SMILES Parse Error: ring closure 2 duplicates bond between atom 9 and atom 10 for input: 'C/C1=C/CC[C@@]2(C)O[C@@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:42] SMILES Parse Error: ring closure 2 duplicates bond between atom 9 and atom 10 for input: 'C/C1=C/CC[C@@]2(C)O[C@@H]2[C@H]2[C@H]2OC(=O)[C@H]2CC1'\n",
      "[23:50:48] SMILES Parse Error: syntax error while parsing: COc1nccccccccccccccccccccc(C(=O)ccccccccccccccccccccc(Cl)ccccccccccccc(Cl)ccccccccccccc(Cl)cccccccccccc(\n",
      "[23:50:48] SMILES Parse Error: Failed parsing SMILES 'COc1nccccccccccccccccccccc(C(=O)ccccccccccccccccccccc(Cl)ccccccccccccc(Cl)ccccccccccccc(Cl)cccccccccccc(' for input: 'COc1nccccccccccccccccccccc(C(=O)ccccccccccccccccccccc(Cl)ccccccccccccc(Cl)ccccccccccccc(Cl)cccccccccccc('\n",
      "[23:50:53] SMILES Parse Error: extra open parentheses for input: 'COc1nccccccccccccccccccccc(C(=O)cccccccccccccccccc(Cl)cccccccccccc(Cl)cccccccccccc(Cl)cccccccccccc(Cl)ccc'\n",
      "[23:50:59] SMILES Parse Error: extra open parentheses for input: 'COc1nccccccccccccccccccc(C(=O)cccccccccccccc(Cl)ccccccccccc(Cl)ccccccccccc(Cl)ccccccccccc(Cl)ccccccccc(Cl)'\n",
      "[23:51:04] SMILES Parse Error: extra open parentheses for input: 'COc1ncccccccccccccccc(C(=O)ccccccccc(Cl)ccccccccc(Cl)ccccccccc(Cl)ccccccccc(Cl)cccccccc(Cl)cccccccc(Cl)cccc'\n",
      "[23:51:10] SMILES Parse Error: extra open parentheses for input: 'COc1nccccccccccccccc(C(=O)cccccc(Cl)ccccccccc(Cl)ccccccccc(Cl)cccccccc(Cl)ccccccc(Cl)cccccccc(Cl)ccccccc(Cl)'\n",
      "[23:51:15] SMILES Parse Error: extra open parentheses for input: 'COc1nccccccccccccc(C(=O)Ncccccc(Cl)cccccccccc(Cl)ccccccccccc(Cl)cccccccccc(Cl)ccccccccc(Cl)ccccccccc(Cl)ccc'\n",
      "[23:51:21] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc(c(c(c(c(c(c(c(c(c(c(c(c(c(c(c(C4)CC3)c(F)cccccccccccccccccccccccccc(F)cccccccccccc(F)c'\n",
      "[23:51:27] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc(c(c(c(c(c(c(c(c(c(c(c(c(c(c(c(C4)CC3)c(F)ccccccccccccccccccccccccccc(F)cccccccccccc(F)'\n",
      "[23:51:32] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc(c(c(c(c(c(c(c(c(c(c(c(c(c(c(c(C4)CC3)c(F)cccccccccccccccccccccccccc(F)ccccccccccc(F)cc'\n",
      "[23:51:38] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc(c(c(c(c(c(c(c(c(c(c(c(c(c(c(C4)CC3)c(F)ccccccccccccccccccc(F)cccccccccc(F)cccccccccc(F'\n",
      "[23:51:43] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc(c(c(c(c(c(c(c(c(c(c(c(c(c(c(c(C4)CC3)c(F)cccccccccccccccccccccc(F)cccccccccc(F)ccccccc'\n",
      "[23:51:49] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc(c(c(c(c(c(c(c(c(c(c(c(c(N3CCN(C4)cccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:51:54] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc(c(c(c(c(c(c(c(c(c(c(N3CCN(C4)cccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:52:00] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc(c(c(c(c(c(c(c(c(c(c(N3CCN(C4)cccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:52:05] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc(c(c(c(c(c(c(c(c(N3CCN(C4)cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:52:11] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc(c(c(c(c(c(c(c(c(c(N3CCN(C4)cccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:52:16] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:52:22] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:52:27] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccccccccccccccccccccccccc(F)ccccccccccccccccccccc'\n",
      "[23:52:33] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:52:39] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccccccc(F)c1'\n",
      "[23:52:44] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(c(c(c(c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:52:44] SMILES Parse Error: extra close parentheses while parsing: COc1ncccccccccc(C(=O)Nccc(C(=O)ccccccc(Cl)ccccccccccccc(Cl)ccccccccccccc(Cl)ccccccccccccc(Cl)ccccc4)c4)c4)\n",
      "[23:52:44] SMILES Parse Error: Failed parsing SMILES 'COc1ncccccccccc(C(=O)Nccc(C(=O)ccccccc(Cl)ccccccccccccc(Cl)ccccccccccccc(Cl)ccccccccccccc(Cl)ccccc4)c4)c4)' for input: 'COc1ncccccccccc(C(=O)Nccc(C(=O)ccccccc(Cl)ccccccccccccc(Cl)ccccccccccccc(Cl)ccccccccccccc(Cl)ccccc4)c4)c4)'\n",
      "[23:52:50] SMILES Parse Error: extra close parentheses while parsing: CNC(=O)O[C@H]1COc2c(N3CCN(C4COC4)CC3)c2)[C@@H]1NC(=O)ccccc1\n",
      "[23:52:50] SMILES Parse Error: Failed parsing SMILES 'CNC(=O)O[C@H]1COc2c(N3CCN(C4COC4)CC3)c2)[C@@H]1NC(=O)ccccc1' for input: 'CNC(=O)O[C@H]1COc2c(N3CCN(C4COC4)CC3)c2)[C@@H]1NC(=O)ccccc1'\n",
      "[23:52:56] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(c(c(c(c(c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:52:56] SMILES Parse Error: unclosed ring for input: 'COc1ncccccccccc(C(=O)Ncc(C(=O)ccccccc(Cl)cccccccccccccc(Cl)cccccccccccccc(Cl)cccccccccccccc(Cl)ccccc4)c4)c'\n",
      "[23:53:01] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccccc(F)c1'\n",
      "[23:53:07] SMILES Parse Error: unclosed ring for input: 'CNC(=O)O[C@H]1COc2c(N3CCN(C4COC4)CC3)cccccccccccccccccccc(F)c1'\n",
      "[23:53:12] SMILES Parse Error: extra open parentheses for input: 'COc1ncccccccc2c(C(=O)Nc(Cl)cccccccccccccccccc(Cl)ccccccccccccccccccc(Cl)cccccccccccccccccccc(Cl)ccccccccc'\n",
      "[23:53:12] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(c(c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccccc'\n",
      "[23:53:18] SMILES Parse Error: unclosed ring for input: 'CNC(=O)O[C@H]1COc2c(N3CCN(C4COC4)CC3)cccccccccccccccc(F)c1'\n",
      "[23:53:23] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(N3CCN(C4COC4)CC3)cccccccccccccccccccccc(F)c1'\n",
      "[23:53:29] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(c(c(N3CCN(C4COC4)CC3)cccccccccccccccccccccccccccccccccccccccccccccccc(F)cccccccccccccc'\n",
      "[23:53:34] SMILES Parse Error: extra close parentheses while parsing: CNC(=O)O[C@H]1COc2c(N3CCN(C4COC4)CC3)ccc2)[C@@H]1NC(=O)cccccccccccc(F)c1\n",
      "[23:53:34] SMILES Parse Error: Failed parsing SMILES 'CNC(=O)O[C@H]1COc2c(N3CCN(C4COC4)CC3)ccc2)[C@@H]1NC(=O)cccccccccccc(F)c1' for input: 'CNC(=O)O[C@H]1COc2c(N3CCN(C4COC4)CC3)ccc2)[C@@H]1NC(=O)cccccccccccc(F)c1'\n",
      "[23:53:40] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccc(F)c1'\n",
      "[23:53:45] SMILES Parse Error: extra close parentheses while parsing: COc1nccc2cc(C(=O)Nc(Cl)cccccccccc(C(=O)NCccccccc(Cl)NCccccccccccc4)c4)c4)c4)c4)c4)c(=O)[nH]c2n1\n",
      "[23:53:45] SMILES Parse Error: Failed parsing SMILES 'COc1nccc2cc(C(=O)Nc(Cl)cccccccccc(C(=O)NCccccccc(Cl)NCccccccccccc4)c4)c4)c4)c4)c4)c(=O)[nH]c2n1' for input: 'COc1nccc2cc(C(=O)Nc(Cl)cccccccccc(C(=O)NCccccccc(Cl)NCccccccccccc4)c4)c4)c4)c4)c4)c(=O)[nH]c2n1'\n",
      "[23:53:45] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccccccccccccc(F)ccccccccccccccccccccccccccccccc'\n",
      "[23:53:51] SMILES Parse Error: extra close parentheses while parsing: CNC(=O)O[C@H]1COc2c(N3CCN(C4COC4)CC3)c2)[C@@H]1NC(=O)ccccccccccccc(F)c1\n",
      "[23:53:51] SMILES Parse Error: Failed parsing SMILES 'CNC(=O)O[C@H]1COc2c(N3CCN(C4COC4)CC3)c2)[C@@H]1NC(=O)ccccccccccccc(F)c1' for input: 'CNC(=O)O[C@H]1COc2c(N3CCN(C4COC4)CC3)c2)[C@@H]1NC(=O)ccccccccccccc(F)c1'\n",
      "[23:53:56] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(c(N3CCN(C4COC4)CC3)ccccccccccccccccccccccccccc(F)c1'\n",
      "[23:54:02] SMILES Parse Error: extra open parentheses for input: 'CNC(=O)O[C@H]1COc2c(c(c(N3CCN(C4COC4)CC3)cccccccccccccccccccccccccc(F)c1'\n",
      "[23:54:02] SMILES Parse Error: extra close parentheses while parsing: COc1nccc2cc(C(=O)Nc(Cl)cccccccc(C(=O)NCccccc(C(=O)NCc4)c4)c4)c4)c4)c4)c4)c(=O)[nH]c2n1\n",
      "[23:54:02] SMILES Parse Error: Failed parsing SMILES 'COc1nccc2cc(C(=O)Nc(Cl)cccccccc(C(=O)NCccccc(C(=O)NCc4)c4)c4)c4)c4)c4)c4)c(=O)[nH]c2n1' for input: 'COc1nccc2cc(C(=O)Nc(Cl)cccccccc(C(=O)NCccccc(C(=O)NCc4)c4)c4)c4)c4)c4)c4)c(=O)[nH]c2n1'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abcb049da43f4cac8d45b13ec7d7f2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[23:54:03] SMILES Parse Error: unclosed ring for input: 'CNC(=O)O[C@H]1COc2c(c(N3CCN(C4COC4)CC3)cc2)[C@@H]1NC(=O)cccccccccc(F)c1'\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset = MassSpecDataset(\n",
    "    pth=mgf_pth,\n",
    "    spec_transform=SpecTokenizer(n_peaks=60),\n",
    "    mol_transform=None\n",
    ")\n",
    "\n",
    "# Init data module\n",
    "data_module = MassSpecDataModule(\n",
    "    dataset=dataset,\n",
    "    split_pth=split_pth,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Init model\n",
    "model = SmilesTransformer(\n",
    "    input_dim=2,\n",
    "    d_model=512,\n",
    "    nhead=8,\n",
    "    num_encoder_layers=4,\n",
    "    num_decoder_layers=4,\n",
    "    dropout=0.0,\n",
    "    smiles_tokenizer=SmilesBPETokenizer(max_len=200),\n",
    "    k_predictions=1,\n",
    "    pre_norm=False,\n",
    "    max_smiles_len=100,\n",
    "    validate_only_loss=True\n",
    ")\n",
    "\n",
    "# Init trainer\n",
    "project = \"MassSpecGymDeNovo\"\n",
    "name = \"SmilesTransformer_debug_overfitting\"\n",
    "logger = pl.loggers.WandbLogger(\n",
    "    project=project,\n",
    "    name=name,\n",
    "    tags=[],\n",
    "    log_model=False,\n",
    ")\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\", max_epochs=100, logger=logger, log_every_n_steps=1, check_val_every_n_epoch=50\n",
    ")\n",
    "\n",
    "# Validate before training\n",
    "data_module.prepare_data()  # Explicit call needed for validate before fit\n",
    "data_module.setup()  # Explicit call needed for validate before fit\n",
    "trainer.validate(model, datamodule=data_module)\n",
    "\n",
    "# Train\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C/C1=C/CC[C@@]2(C)O[C@@H]2[C@H]2OC(=O)[C@H](CN(C)C)[C@@H]2CC1', 'COc1ncc2cc(C(=O)Nc3c(Cl)ccc(C(=O)NCc4cc(Cl)ccc4)c3)c(=O)[nH]c2n1', 'CNC(=O)O[C@H]1COc2c(cc(N3CCN(C4COC4)CC3)cc2)[C@@H]1NC(=O)c1ccc(F)cc1']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C/C1=C/CC[C@@]2(C)O[C@@H]2[C@H]2OC(=O)[C@H]2CC1'], ['C/C1=C/CC[C@@]2(C)O[C@@H]2[C@H]2OC(=O)[C@H]2CC1'], ['CNC(=O)O[C@H]1COc2c(c(N3CCN(C4COC4)CC3)c2)[C@@H]1NC(=O)ccccccccccc(F)c1']]\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    batch = next(iter(data_module.train_dataloader()))\n",
    "    print(batch['mol'])\n",
    "    print(model.decode_smiles(batch))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De novo random chemical generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Seed set to 0\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:187: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(0)\n",
    "\n",
    "# Load dataset\n",
    "# Uncomment the paths to use debugging data containing only 5 spectra\n",
    "dataset = MassSpecDataset(\n",
    "    pth=mgf_pth,\n",
    "    spec_transform=SpecTokenizer(n_peaks=60),\n",
    "    mol_transform=None\n",
    ")\n",
    "\n",
    "# Init data module\n",
    "data_module = MassSpecDataModule(\n",
    "    dataset=dataset,\n",
    "    split_pth=split_pth,\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "# Init model\n",
    "name = \"random_baseline_no_formula\"\n",
    "model = RandomDeNovo(\n",
    "    formula_known=False,\n",
    "    max_top_k=10,\n",
    "    estimate_chem_element_stats=True,\n",
    "    enforce_connectivity=False,\n",
    "    df_test_path=Path(f'../data/test_results/de_novo/{name}.pkl')\n",
    ")\n",
    "\n",
    "# Init logger\n",
    "# You may need to run wandb init first to use the wandb logger\n",
    "# Alternatively set logger = None in Trainer below not to use wandb\n",
    "project = \"MassSpecGymDeNovo\"\n",
    "logger = pl.loggers.WandbLogger(\n",
    "    project=project,\n",
    "    name=name,\n",
    "    tags=[],\n",
    "    log_model=False,\n",
    ")\n",
    "\n",
    "# Init trainer\n",
    "trainer = Trainer(\n",
    "    accelerator=\"cpu\", max_epochs=1, logger=logger, log_every_n_steps=1000,\n",
    "    limit_val_batches=0, num_sanity_val_steps=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory ./MassSpecGymDeNovo/h9oymy96/checkpoints exists and is not empty.\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name | Type | Params\n",
      "------------------------------\n",
      "------------------------------\n",
      "0         Trainable params\n",
      "0         Non-trainable params\n",
      "0         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0a6e3c971a49388d45080a0473feba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a4f545a2b84a979d9472090afb721a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        Test metric                 DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_loss                      0.0\n",
      "    test_num_valid_mols                 10.0\n",
      "    test_top_10_accuracy                0.0\n",
      "test_top_10_max_tanimoto_sim    0.07246376574039459\n",
      "   test_top_10_mces_dist                15.0\n",
      "    test_top_1_accuracy                 0.0\n",
      "test_top_1_max_tanimoto_sim     0.07246376574039459\n",
      "    test_top_1_mces_dist                16.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0,\n",
       "  'test_num_valid_mols': 10.0,\n",
       "  'test_top_1_mces_dist': 16.0,\n",
       "  'test_top_1_max_tanimoto_sim': 0.07246376574039459,\n",
       "  'test_top_1_accuracy': 0.0,\n",
       "  'test_top_10_mces_dist': 15.0,\n",
       "  'test_top_10_max_tanimoto_sim': 0.07246376574039459,\n",
       "  'test_top_10_accuracy': 0.0}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=data_module)\n",
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory ./MassSpecGymDeNovo/h9oymy96/checkpoints exists and is not empty.\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:181: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "   | Name                          | Type       | Params\n",
      "--------------------------------------------------------------\n",
      "0  | train_num_valid_mols          | MeanMetric | 0     \n",
      "1  | train_top_1_mces_dist         | MeanMetric | 0     \n",
      "2  | train_top_1_max_tanimoto_sim  | MeanMetric | 0     \n",
      "3  | train_top_1_accuracy          | MeanMetric | 0     \n",
      "4  | train_top_10_mces_dist        | MeanMetric | 0     \n",
      "5  | train_top_10_max_tanimoto_sim | MeanMetric | 0     \n",
      "6  | train_top_10_accuracy         | MeanMetric | 0     \n",
      "7  | test_num_valid_mols           | MeanMetric | 0     \n",
      "8  | test_top_1_mces_dist          | MeanMetric | 0     \n",
      "9  | test_top_1_max_tanimoto_sim   | MeanMetric | 0     \n",
      "10 | test_top_1_accuracy           | MeanMetric | 0     \n",
      "11 | test_top_10_mces_dist         | MeanMetric | 0     \n",
      "12 | test_top_10_max_tanimoto_sim  | MeanMetric | 0     \n",
      "13 | test_top_10_accuracy          | MeanMetric | 0     \n",
      "--------------------------------------------------------------\n",
      "0         Trainable params\n",
      "0         Non-trainable params\n",
      "0         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=1000). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "# Validate before training\n",
    "data_module.prepare_data()  # Explicit call needed for validate before fit\n",
    "data_module.setup()  # Explicit call needed for validate before fit\n",
    "trainer.validate(model, datamodule=data_module)\n",
    "\n",
    "# Train\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-pa ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/adamo/miniconda3/envs/MSG2/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4978a6bfc7b41b9923d98c2a72b65e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        Test metric                 DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         test_loss                      0.0\n",
      "    test_num_valid_mols                 10.0\n",
      "    test_top_10_accuracy                0.0\n",
      "test_top_10_max_tanimoto_sim    0.07246376574039459\n",
      "   test_top_10_mces_dist                15.0\n",
      "    test_top_1_accuracy                 0.0\n",
      "test_top_1_max_tanimoto_sim     0.07246376574039459\n",
      "    test_top_1_mces_dist                16.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.0,\n",
       "  'test_num_valid_mols': 10.0,\n",
       "  'test_top_1_mces_dist': 16.0,\n",
       "  'test_top_1_max_tanimoto_sim': 0.07246376574039459,\n",
       "  'test_top_1_accuracy': 0.0,\n",
       "  'test_top_10_mces_dist': 15.0,\n",
       "  'test_top_10_max_tanimoto_sim': 0.07246376574039459,\n",
       "  'test_top_10_accuracy': 0.0}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSG2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
